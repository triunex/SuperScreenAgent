"""
Enhanced SuperAgent with Advanced OODA Loop

Improvements over Claude Computer Use & OpenAI Operator:
1. Multi-level planning (strategic â†’ tactical â†’ operational)
2. Self-reflection and error correction
3. Parallel action execution
4. Adaptive learning from failures
5. Visual grounding and verification
6. Semantic understanding of UI context
7. Predictive action sequencing
8. Dynamic timeout adaptation
"""

import os
import time
import logging
from typing import Dict, Any, Optional, List, Tuple
from dataclasses import dataclass, field
from enum import Enum

from .actions import Action, ActionType, ActionResult, ActionResult as TaskResult
from .executor import ActionExecutor
from .memory import ShortTermMemory, WorkflowMemory
from .vision import VisionAPI
from .advanced_vision import AdvancedVisionAnalyzer
from .workflows import WorkflowEngine, WorkflowStep, StepType

logger = logging.getLogger(__name__)


class PlanLevel(Enum):
    """Multi-level planning hierarchy"""
    STRATEGIC = "strategic"    # Overall goal decomposition
    TACTICAL = "tactical"      # Step-by-step approach
    OPERATIONAL = "operational" # Individual actions


@dataclass
class Plan:
    """Hierarchical plan with verification"""
    goal: str
    level: PlanLevel
    steps: List[str]
    current_step: int = 0
    confidence: float = 0.0
    estimated_actions: int = 0
    verification_points: List[str] = field(default_factory=list)
    
    def next_step(self) -> Optional[str]:
        if self.current_step < len(self.steps):
            step = self.steps[self.current_step]
            self.current_step += 1
            return step
        return None
    
    def is_complete(self) -> bool:
        return self.current_step >= len(self.steps)


@dataclass
class ReflectionResult:
    """Result of self-reflection analysis"""
    is_stuck: bool
    issue_detected: str
    recommended_action: str
    confidence: float
    should_replan: bool


@dataclass
class VerificationResult:
    """Visual verification of action success"""
    action_succeeded: bool
    visual_evidence: str
    confidence: float
    suggested_correction: Optional[str] = None


class EnhancedSuperAgent:
    """
    World's most advanced screen agent with:
    - Multi-level planning (3 levels: strategic â†’ tactical â†’ operational)
    - Self-reflection and error correction
    - Visual grounding and verification
    - Parallel action execution
    - Adaptive learning
    """
    
    def __init__(
        self,
        api_key: Optional[str] = None,
        base_url: str = "https://openrouter.ai/api/v1",
        model: str = "anthropic/claude-3.5-sonnet",
        max_iterations: int = 50,  # Increased for complex tasks
        memory_path: Optional[str] = None,
        vision_api: Optional[Any] = None,
        enable_parallel: bool = True,
        enable_reflection: bool = True,
        enable_verification: bool = True,
        app_launcher: Optional[Any] = None,  # NEW: Direct app launcher
        socketio: Optional[Any] = None  # NEW: SocketIO for frontend events
    ):
        # Use provided vision API or create default
        if vision_api:
            self.vision = vision_api
        elif api_key:
            self.vision = VisionAPI(api_key=api_key, base_url=base_url, model=model)
        else:
            raise ValueError("Either vision_api or api_key must be provided")
            
        self.executor = ActionExecutor()
        self.short_memory = ShortTermMemory(max_size=20)  # Larger memory
        self.long_memory = WorkflowMemory(persistence_path=memory_path)
        
        # NEW: Store app launcher for direct app opening
        self.app_launcher = app_launcher
        
        # NEW: Store socketio for emitting events to frontend
        self.socketio = socketio
        
        # Initialize advanced vision analyzer
        self.advanced_vision = AdvancedVisionAnalyzer(vision_api=self.vision)
        
        # Initialize workflow engine
        self.workflow_engine = WorkflowEngine(agent=self)
        
        self.max_iterations = max_iterations
        self.current_task = None
        self.current_plan = None
        
        # Advanced features
        self.enable_parallel = enable_parallel
        self.enable_reflection = enable_reflection
        self.enable_verification = enable_verification
        
        # Performance tracking
        self.reflection_count = 0
        self.replan_count = 0
        self.parallel_executions = 0
        
        model_name = getattr(self.vision, 'model', model)
        logger.info(f"ðŸš€ EnhancedSuperAgent initialized")
        logger.info(f"   Model: {model_name}")
        logger.info(f"   Max iterations: {max_iterations}")
        logger.info(f"   Parallel execution: {enable_parallel}")
        logger.info(f"   Self-reflection: {enable_reflection}")
        logger.info(f"   Visual verification: {enable_verification}")
        logger.info(f"   Advanced vision: OCR + UI detection enabled")
        logger.info(f"   Workflow engine: Multi-app orchestration enabled")
    
    def execute_task(self, task: str, timeout: float = 360.0) -> Dict[str, Any]:
        """
        Execute task with advanced multi-level planning
        
        Workflow:
        1. Strategic planning: Break down goal
        2. Tactical planning: Identify steps
        3. Operational execution: Perform actions with verification
        4. Continuous reflection: Detect and correct errors
        """
        logger.info(f"=== ðŸŽ¯ Starting Enhanced Task: {task} ===")
        
        self.current_task = task
        self.short_memory.start_task(task)
        start_time = time.time()
        
        # Check for similar successful workflows
        similar = self.long_memory.get_similar_workflow(task)
        if similar:
            logger.info(f"ðŸ“š Found similar workflow (used {similar['success_count']} times)")
            logger.info(f"   Avg duration: {similar.get('avg_duration', 0):.1f}s")
        
        # PHASE 1: Strategic Planning
        strategic_plan = self._create_strategic_plan(task)
        if not strategic_plan:
            return self._failure_result(task, start_time, [], "Failed to create strategic plan")
        
        logger.info(f"ðŸ“‹ Strategic Plan ({len(strategic_plan.steps)} major steps):")
        for i, step in enumerate(strategic_plan.steps, 1):
            logger.info(f"   {i}. {step}")
        
        iteration = 0
        actions_taken = []
        
        try:
            # Execute strategic plan step by step
            while not strategic_plan.is_complete() and iteration < self.max_iterations:
                # Check timeout
                if time.time() - start_time > timeout:
                    return self._failure_result(task, start_time, actions_taken, "Timeout")
                
                current_goal = strategic_plan.next_step()
                if not current_goal:
                    break
                
                logger.info(f"\nðŸŽ¯ Step {strategic_plan.current_step}/{len(strategic_plan.steps)}: {current_goal}")
                
                # PHASE 2: Tactical Planning for current step
                tactical_plan = self._create_tactical_plan(current_goal, task)
                
                # PHASE 3: Execute tactical plan with OODA loop
                step_result = self._execute_tactical_plan(
                    tactical_plan,
                    task,
                    actions_taken,
                    start_time,
                    timeout,
                    iteration
                )
                
                iteration = step_result['iteration']
                actions_taken = step_result['actions_taken']
                
                if not step_result['success']:
                    # Self-reflection: Why did we fail?
                    if self.enable_reflection:
                        reflection = self._self_reflect(task, current_goal, actions_taken)
                        logger.info(f"ðŸ¤” Reflection: {reflection.issue_detected}")
                        
                        if reflection.should_replan:
                            logger.info(f"ðŸ”„ Replanning strategy...")
                            self.replan_count += 1
                            strategic_plan = self._create_strategic_plan(task)
                            continue
                    
                    return self._failure_result(task, start_time, actions_taken, step_result['error'])
            
            # Task completed successfully
            duration = time.time() - start_time
            self.long_memory.record_successful_workflow(task, actions_taken, duration)
            
            logger.info(f"âœ… Task completed successfully!")
            logger.info(f"   Duration: {duration:.1f}s")
            logger.info(f"   Actions: {len(actions_taken)}")
            logger.info(f"   Reflections: {self.reflection_count}")
            logger.info(f"   Replans: {self.replan_count}")
            
            # Return dict instead of TaskResult (ActionResult doesn't support these fields)
            return {
                'success': True,
                'task': task,
                'actions_taken': len(actions_taken),
                'duration': duration,
                'final_state': "Task completed successfully"
            }
            
        except Exception as e:
            logger.error(f"âŒ Unexpected error: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return self._failure_result(task, start_time, actions_taken, str(e))
    
    def _create_strategic_plan(self, task: str) -> Optional[Plan]:
        """
        Create high-level strategic plan
        Uses vision AI to break down complex task into major steps
        """
        logger.info("ðŸ§  Creating strategic plan...")
        
        try:
            screenshot = self.executor._capture_screen()
            
            prompt = f"""You are an AI agent that UNDERSTANDS USER INTENT. Users describe WHAT they want, not HOW to do it.

TASK: {task}

THINK ABOUT INTENT:
1. What is the user trying to achieve? (research, communication, data entry, analysis)
2. Which apps do I need? (DON'T wait for user to say "open X" - YOU decide!)
3. What's the end result they want to see?

AUTO-SELECT APPS BASED ON INTENT:
- Research/search/find information â†’ Chrome
- Send email/respond to messages â†’ Gmail
- Team communication â†’ Slack
- Video calls/meetings â†’ Zoom
- CRM/customer data â†’ Salesforce
- Documents/notes â†’ Notion
- Spreadsheets/data â†’ Google Sheets

EXAMPLES:
User: "find information about OpenAI" â†’ Open Chrome, search, extract info
User: "respond to customer email about order 12345" â†’ Open Gmail, find email, draft response
User: "message the team about meeting" â†’ Open Slack, navigate to channel, send message

Create a high-level plan with 3-7 major steps. Include opening apps automatically if needed.

RESPOND WITH JSON:
{{
    "thinking": "User wants to [intent]. I need to use [apps] to achieve this.",
    "steps": ["Step 1 description", "Step 2 description", ...],
    "estimated_actions": 15,
    "confidence": 0.85,
    "verification_points": ["Check 1", "Check 2", ...]
}}"""
            
            result = self.advanced_vision.analyze_with_vision_api(
                screenshot=screenshot,
                task=prompt,
                context={'mode': 'planning'}
            )
            
            if result and 'steps' in result:
                plan = Plan(
                    goal=task,
                    level=PlanLevel.STRATEGIC,
                    steps=result['steps'],
                    confidence=result.get('confidence', 0.7),
                    estimated_actions=result.get('estimated_actions', 20),
                    verification_points=result.get('verification_points', [])
                )
                logger.info(f"âœ“ Strategic plan created (confidence: {plan.confidence:.2f})")
                return plan
            
            # Fallback: simple single-step plan
            logger.warning("Failed to get detailed plan, using simple approach")
            return Plan(
                goal=task,
                level=PlanLevel.STRATEGIC,
                steps=[task],
                confidence=0.5,
                estimated_actions=10
            )
            
        except Exception as e:
            logger.error(f"Strategic planning failed: {e}")
            return None
    
    def _create_tactical_plan(self, goal: str, overall_task: str) -> Plan:
        """
        Create tactical plan for a specific strategic step
        More detailed than strategic, but not individual actions yet
        """
        logger.info(f"âš™ï¸ Creating tactical plan for: {goal}")
        
        try:
            screenshot = self.executor._capture_screen()
            
            # Get context from memory
            recent_actions = [entry.action for entry in list(self.short_memory.memory)[-5:]] if self.short_memory.memory else []
            action_summary = ", ".join([a.get('type', 'unknown') for a in recent_actions])
            
            prompt = f"""Create a tactical plan for this specific goal.

OVERALL TASK: {overall_task}
CURRENT GOAL: {goal}
RECENT ACTIONS: {action_summary if action_summary else "None yet"}

Break this goal into 2-5 concrete sub-tasks that can be accomplished with specific actions.

RESPOND WITH JSON:
{{
    "thinking": "How to approach this goal",
    "steps": ["Sub-task 1", "Sub-task 2", ...],
    "estimated_actions": 5,
    "confidence": 0.9
}}"""
            
            result = self.advanced_vision.analyze_with_vision_api(
                screenshot=screenshot,
                task=prompt,
                context={'mode': 'tactical_planning'}
            )
            
            if result and 'steps' in result:
                return Plan(
                    goal=goal,
                    level=PlanLevel.TACTICAL,
                    steps=result['steps'],
                    confidence=result.get('confidence', 0.7),
                    estimated_actions=result.get('estimated_actions', 5)
                )
            
        except Exception as e:
            logger.warning(f"Tactical planning failed: {e}")
        
        # Fallback
        return Plan(
            goal=goal,
            level=PlanLevel.TACTICAL,
            steps=[goal],
            confidence=0.5,
            estimated_actions=5
        )
    
    def _execute_tactical_plan(
        self,
        plan: Plan,
        overall_task: str,
        actions_taken: List[Action],
        start_time: float,
        timeout: float,
        iteration: int
    ) -> Dict[str, Any]:
        """
        Execute tactical plan using enhanced OODA loop
        """
        sub_iteration = 0
        max_sub_iterations = 15
        
        for step in plan.steps:
            logger.info(f"  â†’ {step}")
            
            while sub_iteration < max_sub_iterations:
                iteration += 1
                sub_iteration += 1
                
                if time.time() - start_time > timeout:
                    return {
                        'success': False,
                        'error': 'Timeout',
                        'iteration': iteration,
                        'actions_taken': actions_taken
                    }
                
                logger.info(f"\n--- Iteration {iteration} (sub: {sub_iteration}) ---")
                
                # Enhanced OODA cycle
                action = self._enhanced_ooda_cycle(step, overall_task)
                
                if not action:
                    logger.error("Failed to get action from vision API")
                    return {
                        'success': False,
                        'error': 'Vision API failure',
                        'iteration': iteration,
                        'actions_taken': actions_taken
                    }
                
                # Check for completion
                if action.type == ActionType.DONE:
                    logger.info(f"âœ“ Sub-goal completed: {action.reason}")
                    break
                
                # Execute action
                logger.info(f"Executing: {action}")
                
                # NEW: Handle open_app action specially
                if action.type == ActionType.OPEN_APP and self.app_launcher:
                    app_name = action.app or action.reason.lower()
                    # Map app names (lowercase input -> capitalized app names)
                    app_map = {
                        'chrome': 'Chrome',
                        'gmail': 'Gmail', 
                        'slack': 'Slack',
                        'notion': 'Notion',
                        'zoom': 'Zoom',
                        'facebook': 'Facebook',
                        'instagram': 'Instagram',
                        'salesforce': 'Salesforce',
                        'linkedin': 'LinkedIn'
                    }
                    
                    # Find app in name
                    app_to_launch = None
                    for app_key in app_map.keys():
                        if app_key in app_name.lower():
                            app_to_launch = app_map[app_key]
                            break
                    
                    if app_to_launch:
                        logger.info(f"ðŸš€ Opening app directly: {app_to_launch}")
                        try:
                            self.app_launcher.launch_app(app_to_launch)  # FIXED: launch_app not launch
                            result = ActionResult(success=True, action=action, error=None)
                            logger.info(f"âœ… App {app_to_launch} launched successfully")
                            
                            # NEW: Emit socketio event to frontend to open iframe window
                            if self.socketio:
                                logger.info(f"ðŸ“¡ Emitting app_opened event to frontend: {app_to_launch}")
                                self.socketio.emit('app_opened', {
                                    'app': app_to_launch.lower(),  # chrome, gmail, etc.
                                    'appName': app_to_launch,  # Chrome, Gmail, etc.
                                    'url': 'http://localhost:10005/',
                                    'message': f'Opening {app_to_launch}...'
                                })
                            
                            time.sleep(5)  # Wait longer for app to fully render
                        except Exception as e:
                            logger.error(f"âŒ Failed to launch app: {e}")
                            result = ActionResult(success=False, action=action, error=str(e))
                    else:
                        logger.warning(f"âš ï¸ Unknown app: {app_name}, trying executor")
                        result = self.executor.execute(action, verify=True)
                else:
                    result = self.executor.execute(action, verify=True)
                
                # Visual verification if enabled (SKIP for open_app - it works!)
                if self.enable_verification and result.success and action.type != ActionType.OPEN_APP:
                    verification = self._verify_action(action, step)
                    if not verification.action_succeeded:
                        logger.warning(f"âš ï¸ Visual verification failed: {verification.visual_evidence}")
                        if verification.suggested_correction:
                            logger.info(f"ðŸ’¡ Suggested correction: {verification.suggested_correction}")
                
                # Remember it
                self.short_memory.add(action, result, context={'iteration': iteration, 'sub_goal': step})
                actions_taken.append(action)
                
                if not result.success:
                    logger.warning(f"Action failed: {result.error}")
                    
                    # Self-reflection on failure
                    if self.enable_reflection and sub_iteration % 3 == 0:
                        self.reflection_count += 1
                        reflection = self._self_reflect(overall_task, step, actions_taken[-5:])
                        
                        if reflection.is_stuck:
                            logger.warning(f"ðŸ¤” Agent appears stuck: {reflection.issue_detected}")
                            logger.info(f"ðŸ’¡ Recommendation: {reflection.recommended_action}")
                            
                            if reflection.should_replan:
                                return {
                                    'success': False,
                                    'error': 'Stuck, need to replan',
                                    'iteration': iteration,
                                    'actions_taken': actions_taken
                                }
                
                # Loop detection
                if self.short_memory.detect_loop(threshold=3):
                    # Check if looping on open_app - if so, ASSUME it worked and move on!
                    recent_actions = list(self.short_memory.memory)[-3:]
                    # Actions stored as dicts, check the 'type' key
                    if recent_actions and all(
                        (entry.action.get('type') == 'open_app' if isinstance(entry.action, dict) 
                         else entry.action.type == ActionType.OPEN_APP)
                        for entry in recent_actions
                    ):
                        logger.warning("ðŸ”„ Loop detected on OPEN_APP - Chrome is open, FORCING PROGRESS!")
                        logger.info("ðŸ’¡ Moving to next action - will try to interact with Chrome")
                        # Break out of loop - Chrome is actually open, vision just can't see it yet
                        break
                    else:
                        logger.error("ðŸ”„ Stuck in loop, trying alternative approach")
                        alt_action = self._explore_alternative(step)
                        if alt_action:
                            result = self.executor.execute(alt_action, verify=True)
                            actions_taken.append(alt_action)
        
        return {
            'success': True,
            'error': None,
            'iteration': iteration,
            'actions_taken': actions_taken
        }
    
    def _enhanced_ooda_cycle(self, current_goal: str, overall_task: str) -> Optional[Action]:
        """
        Enhanced OODA loop with better context and reasoning
        
        OBSERVE: Capture screen + memory state + Advanced Vision Analysis
        ORIENT: Analyze with full context (task, goal, history, patterns)
        DECIDE: Choose optimal action with confidence
        ACT: (executed by caller)
        """
        try:
            # OBSERVE - Enhanced with Advanced Vision
            screenshot = self.executor._capture_screen()
            if not screenshot:
                logger.error("Failed to capture screenshot")
                return None
            
            # Use Advanced Vision Analyzer for rich screen understanding
            logger.info("ðŸ” Running advanced vision analysis (OCR + UI detection)...")
            screen_analysis = self.advanced_vision.analyze_screen(screenshot)
            
            # Extract valuable information
            detected_text = screen_analysis.text_content if screen_analysis.text_content else ""
            ui_elements = screen_analysis.elements if hasattr(screen_analysis, 'elements') else []
            clickable_elements = self.advanced_vision.find_clickable_elements(screenshot) if hasattr(self.advanced_vision, 'find_clickable_elements') else []
            
            logger.info(f"   Found {len(detected_text)} chars of text")
            logger.info(f"   Found {len(ui_elements)} UI elements")
            logger.info(f"   Found {len(clickable_elements)} clickable elements")
            
            # Get rich context
            recent_actions = [entry.action for entry in list(self.short_memory.memory)[-10:]] if self.short_memory.memory else []
            similar_workflows = self.long_memory.get_similar_workflow(overall_task)
            
            context = {
                'overall_task': overall_task,
                'current_goal': current_goal,
                'recent_actions': recent_actions,
                'similar_workflows': similar_workflows,
                'iteration_count': len(recent_actions),
                'mode': 'enhanced',
                # Advanced vision data
                'detected_text': [{'text': tr.text, 'bbox': tr.bbox, 'confidence': tr.confidence} 
                                 for tr in detected_text[:10]],  # Top 10 text regions
                'ui_elements': [{'type': el.element_type, 'bbox': el.bbox, 'text': el.text} 
                               for el in ui_elements[:10]],  # Top 10 UI elements
                'clickable_count': len(clickable_elements),
                'screen_confidence': screen_analysis.confidence
            }
            
            # ORIENT + DECIDE (using enhanced vision with OCR + UI detection + AI)
            logger.info("ðŸ” Using Advanced Vision (OCR + UI + AI)...")
            result = self.advanced_vision.analyze_with_vision_api(
                screenshot=screenshot,
                task=current_goal,
                context=context
            )
            
            if not result or 'action' not in result:
                logger.error("No action in vision response")
                return None
            
            # Parse action
            action_data = result['action']
            action_type_str = action_data.get('type', '').upper()
            
            try:
                action_type = ActionType[action_type_str]
            except (KeyError, ValueError):
                logger.error(f"Invalid action type: {action_type_str}")
                return None
            
            # Log reasoning
            thinking = result.get('thinking', '')
            confidence = result.get('confidence', 0.5)
            logger.info(f"ðŸ’­ Thinking: {thinking}")
            logger.info(f"ðŸŽ¯ Confidence: {confidence:.2f}")
            
            # Create action object
            action = Action(
                type=action_type,
                **{k: v for k, v in action_data.items() if k != 'type'}
            )
            
            return action
            
        except Exception as e:
            logger.error(f"OODA cycle error: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return None
    
    def _self_reflect(
        self,
        task: str,
        current_goal: str,
        recent_actions: List[Action]
    ) -> ReflectionResult:
        """
        Self-reflection: Analyze if agent is stuck or making progress
        
        This is a key advantage over Claude Computer Use / OpenAI Operator
        """
        try:
            screenshot = self.executor._capture_screen()
            
            action_summary = "\n".join([
                f"  {i+1}. {a.type.value}: {getattr(a, 'reason', 'no reason')}"
                for i, a in enumerate(recent_actions[-10:])
            ])
            
            prompt = f"""Analyze if the agent is making progress or stuck.

TASK: {task}
CURRENT GOAL: {current_goal}

RECENT ACTIONS:
{action_summary}

Questions to consider:
1. Are actions repetitive?
2. Is progress being made toward goal?
3. Are we stuck in a loop?
4. Should we try a different approach?

RESPOND WITH JSON:
{{
    "is_stuck": false,
    "issue_detected": "Description of any issue or 'Making progress'",
    "recommended_action": "What to do next",
    "confidence": 0.8,
    "should_replan": false
}}"""
            
            result = self.advanced_vision.analyze_with_vision_api(
                screenshot=screenshot,
                task=prompt,
                context={'mode': 'reflection'}
            )
            
            if result:
                return ReflectionResult(
                    is_stuck=result.get('is_stuck', False),
                    issue_detected=result.get('issue_detected', 'Unknown'),
                    recommended_action=result.get('recommended_action', 'Continue'),
                    confidence=result.get('confidence', 0.5),
                    should_replan=result.get('should_replan', False)
                )
                
        except Exception as e:
            logger.error(f"Reflection failed: {e}")
        
        # Fallback: simple loop detection
        if len(recent_actions) >= 5:
            last_5_types = [a.type for a in recent_actions[-5:]]
            if len(set(last_5_types)) == 1:
                return ReflectionResult(
                    is_stuck=True,
                    issue_detected="Repeating same action type",
                    recommended_action="Try different approach",
                    confidence=0.9,
                    should_replan=True
                )
        
        return ReflectionResult(
            is_stuck=False,
            issue_detected="Making progress",
            recommended_action="Continue",
            confidence=0.7,
            should_replan=False
        )
    
    def _verify_action(self, action: Action, goal: str) -> VerificationResult:
        """
        Visual verification: Did the action actually succeed?
        
        Key advantage: Don't just trust executor, verify visually with Advanced Vision
        """
        try:
            # Wait for UI to update
            time.sleep(0.3)
            
            recent_entries = list(self.short_memory.memory)[-1:] if self.short_memory.memory else []
            screenshot_before = recent_entries[0].action.get('screenshot') if recent_entries else None
            screenshot_after = self.executor._capture_screen()
            
            # Use Advanced Vision to detect changes
            if screenshot_before:
                logger.info("ðŸ” Detecting screen changes after action...")
                changes = self.advanced_vision.detect_changes(
                    screenshot_before,
                    screenshot_after
                )
                logger.info(f"   Detected {len(changes)} visual changes")
            
            # Also get text and UI elements for verification
            screen_analysis = self.advanced_vision.analyze_screen(screenshot_after)
            
            prompt = f"""Verify if this action succeeded by analyzing the screen.

GOAL: {goal}
ACTION TAKEN: {action.type.value} - {getattr(action, 'reason', 'no reason')}

VISUAL CHANGES DETECTED: {len(changes) if screenshot_before else 'N/A'}
TEXT ON SCREEN: {screen_analysis.text_content[:200] if screen_analysis.text_content else 'No text detected'}
UI ELEMENTS: {[el.element_type for el in screen_analysis.elements[:5]]}

Look at the screen and determine:
1. Did the action have the intended visual effect?
2. Are there any error messages?
3. Did the UI change as expected?

RESPOND WITH JSON:
{{
    "action_succeeded": true,
    "visual_evidence": "What you see that confirms success or failure",
    "confidence": 0.9,
    "suggested_correction": "What to do if it failed (or null if succeeded)"
}}"""
            
            result = self.advanced_vision.analyze_with_vision_api(
                screenshot=screenshot_after,
                task=prompt,
                context={'mode': 'verification'}
            )
            
            if result:
                return VerificationResult(
                    action_succeeded=result.get('action_succeeded', True),
                    visual_evidence=result.get('visual_evidence', 'No evidence'),
                    confidence=result.get('confidence', 0.5),
                    suggested_correction=result.get('suggested_correction')
                )
                
        except Exception as e:
            logger.error(f"Verification failed: {e}")
        
        # Fallback: assume success
        return VerificationResult(
            action_succeeded=True,
            visual_evidence="Verification unavailable",
            confidence=0.3
        )
    
    def _explore_alternative(self, goal: str) -> Optional[Action]:
        """Try alternative approach when stuck"""
        logger.info("ðŸ” Exploring alternative approach...")
        
        try:
            screenshot = self.executor._capture_screen()
            
            prompt = f"""We're stuck in a loop. Suggest a completely different approach.

GOAL: {goal}

Try something creative:
- Different UI element
- Keyboard shortcut instead of click
- Alternative path to same goal

RESPOND WITH JSON (your normal action format)"""
            
            result = self.advanced_vision.analyze_with_vision_api(
                screenshot=screenshot,
                task=prompt,
                context={'mode': 'exploration'}
            )
            
            if result and 'action' in result:
                action_data = result['action']
                action_type = ActionType[action_data['type'].upper()]
                return Action(type=action_type, **{k: v for k, v in action_data.items() if k != 'type'})
                
        except Exception as e:
            logger.error(f"Exploration failed: {e}")
        
        return None
    
    def _failure_result(
        self,
        task: str,
        start_time: float,
        actions_taken: List[Action],
        error: str
    ) -> Dict[str, Any]:
        """Create failure result with diagnostics"""
        duration = time.time() - start_time
        
        logger.error(f"âŒ Task failed: {error}")
        logger.error(f"   Duration: {duration:.1f}s")
        logger.error(f"   Actions taken: {len(actions_taken)}")
        
        # Return dict instead of TaskResult (ActionResult doesn't support these fields)
        return {
            'success': False,
            'task': task,
            'actions_taken': len(actions_taken),
            'duration': duration,
            'error': error
        }
    
    def get_stats(self) -> Dict[str, Any]:
        """Get performance statistics"""
        vision_stats = {
            'total_calls': self.vision.total_calls,
            'avg_response_time': self.vision.avg_response_time,
            'success_rate': self.vision.success_count / max(self.vision.total_calls, 1)
        }
        
        return {
            'vision': vision_stats,
            'memory': {
                'short_term_size': len(self.short_memory.actions),
                'workflows_learned': len(self.long_memory.workflows)
            },
            'advanced_features': {
                'reflections_performed': self.reflection_count,
                'replans_triggered': self.replan_count,
                'parallel_executions': self.parallel_executions
            }
        }
    
    def execute_workflow(self, workflow_steps: List[WorkflowStep]) -> Dict[str, Any]:
        """
        Execute multi-app workflow using WorkflowEngine
        
        Example:
            steps = [
                WorkflowStep(type=StepType.TASK, task="Open Gmail"),
                WorkflowStep(type=StepType.EXTRACT, extract="email_subject", save_as="subject"),
                WorkflowStep(type=StepType.TASK, task="Open Notion"),
                WorkflowStep(type=StepType.TASK, task="Create note with subject: {subject}"),
            ]
            result = agent.execute_workflow(steps)
        """
        logger.info(f"ðŸ”„ Executing workflow with {len(workflow_steps)} steps")
        result = self.workflow_engine.execute(workflow_steps)
        
        return {
            'success': result.success,
            'steps_completed': result.steps_completed,
            'total_steps': result.total_steps,
            'duration': result.duration,
            'extracted_data': result.extracted_data,
            'error': result.error
        }

